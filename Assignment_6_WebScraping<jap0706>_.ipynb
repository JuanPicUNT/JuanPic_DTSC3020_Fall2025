{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanPicUNT/JuanPic_DTSC3020_Fall2025/blob/main/Assignment_6_WebScraping%3Cjap0706%3E_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_de5Eq4u-tR"
      },
      "source": [
        "# Assignment 6 (4 points) — Web Scraping\n",
        "\n",
        "In this assignment you will complete **two questions**. The **deadline is posted on Canvas**.\n"
      ],
      "id": "H_de5Eq4u-tR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHwamZMu-tX"
      },
      "source": [
        "## Assignment Guide (Read Me First)\n",
        "\n",
        "- This notebook provides an **Install Required Libraries** cell and a **Common Imports & Polite Headers** cell. Run them first.\n",
        "- Each question includes a **skeleton**. The skeleton is **not** a solution; it is a lightweight scaffold you may reuse.\n",
        "- Under each skeleton you will find a **“Write your answer here”** code cell. Implement your scraping, cleaning, and saving logic there.\n",
        "- When your code is complete, run the **Runner** cell to print a Top‑15 preview and save the CSV.\n",
        "- Expected outputs:\n",
        "  - **Q1:** `data_q1.csv` + Top‑15 sorted by the specified numeric column.\n",
        "  - **Q2:** `data_q2.csv` + Top‑15 sorted by `points`.\n"
      ],
      "id": "4PHwamZMu-tX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7DLq9nEu-tZ"
      },
      "outputs": [],
      "source": [
        "1) #Install Required Libraries\n",
        "!pip -q install requests beautifulsoup4 lxml pandas\n",
        "print(\"Dependencies installed.\")\n"
      ],
      "id": "I7DLq9nEu-tZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_A9RuPu-tb"
      },
      "source": [
        "### 2) Common Imports & Polite Headers"
      ],
      "id": "ug_A9RuPu-tb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov8pXh65u-tc"
      },
      "outputs": [],
      "source": [
        "# Common Imports & Polite Headers\n",
        "import re, sys, pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "HEADERS = {\"User-Agent\": (\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0 Safari/537.36\")}\n",
        "def fetch_html(url: str, timeout: int = 20) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "def flatten_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [\" \".join([str(x) for x in tup if str(x)!=\"nan\"]).strip()\n",
        "                      for tup in df.columns.values]\n",
        "    else:\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "print(\"Common helpers loaded.\")\n"
      ],
      "id": "Ov8pXh65u-tc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0GO7zzu-td"
      },
      "source": [
        "## Question 1 — IBAN Country Codes (table)\n",
        "**URL:** https://www.iban.com/country-codes  \n",
        "**Extract at least:** `Country`, `Alpha-2`, `Alpha-3`, `Numeric` (≥4 cols; you may add more)  \n",
        "**Clean:** trim spaces; `Alpha-2/Alpha-3` → **UPPERCASE**; `Numeric` → **int** (nullable OK)  \n",
        "**Output:** write **`data_q1.csv`** and **print a Top-15** sorted by `Numeric` (desc, no charts)  \n",
        "**Deliverables:** notebook + `data_q1.csv` + short `README.md` (URL, steps, 1 limitation)\n",
        "\n",
        "**Tip:** You can use `pandas.read_html(html)` to read tables and then pick one with ≥3 columns.\n"
      ],
      "id": "km0GO7zzu-td"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1_skeleton",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "61c99795-e101-42dd-8b37-8eb8b79be8eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3295105108.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Q1 Skeleton (fill the TODOs) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mq1_read_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \"\"\"Return the first table with >= 3 columns from the HTML.\n\u001b[1;32m      4\u001b[0m     \u001b[0mTODO\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimplement\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpick\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreasonable\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mflatten\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# --- Q1 Skeleton (fill the TODOs) ---\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\n",
        "    TODO: implement with pd.read_html(html), pick a reasonable table, then flatten headers.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_read_table\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\n",
        "    TODO: implement cleaning steps.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_clean\")\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_sort_top\")\n"
      ],
      "id": "q1_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a144ea2-34fb-421e-874d-7d5bab09fea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Country Alpha2 Alpha3  Numeric\n",
            "247                                             Zambia     ZM    ZMB      894\n",
            "246                                              Yemen     YE    YEM      887\n",
            "192                                              Samoa     WS    WSM      882\n",
            "244                                  Wallis and Futuna     WF    WLF      876\n",
            "240                 Venezuela (Bolivarian Republic of)     VE    VEN      862\n",
            "238                                         Uzbekistan     UZ    UZB      860\n",
            "237                                            Uruguay     UY    URY      858\n",
            "35                                        Burkina Faso     BF    BFA      854\n",
            "243                              Virgin Islands (U.S.)     VI    VIR      850\n",
            "236                     United States of America (the)     US    USA      840\n",
            "219                       Tanzania, United Republic of     TZ    TZA      834\n",
            "108                                        Isle of Man     IM    IMN      833\n",
            "113                                             Jersey     JE    JEY      832\n",
            "92                                            Guernsey     GG    GGY      831\n",
            "234  United Kingdom of Great Britain and Northern I...     GB    GBR      826\n"
          ]
        }
      ],
      "source": [
        "# Q1 — Write your answer here\n",
        "import pandas as pd\n",
        "\n",
        "URL = \"https://www.iban.com/country-codes\"\n",
        "\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\"\"\"\n",
        "    tables = pd.read_html(html)\n",
        "    # pick the first table meeting the criteria\n",
        "    for df in tables:\n",
        "        if df.shape[1] >= 3:\n",
        "            return df\n",
        "    raise ValueError(\"No table found with >=3 columns\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha‑2/Alpha‑3, cast Numeric to int (nullable), drop invalids.\"\"\"\n",
        "    # Assuming columns like \"Country\", \"Alpha‑2 code\", \"Alpha‑3 code\", \"Numeric\"\n",
        "    df = df.copy()\n",
        "    # rename columns more simply\n",
        "    df = df.rename(columns={\n",
        "        df.columns[0]: 'Country',\n",
        "        df.columns[1]: 'Alpha2',\n",
        "        df.columns[2]: 'Alpha3',\n",
        "        df.columns[3]: 'Numeric'\n",
        "    })\n",
        "    # strip whitespace\n",
        "    df['Country'] = df['Country'].str.strip()\n",
        "    df['Alpha2']  = df['Alpha2'].str.strip().str.upper()\n",
        "    df['Alpha3']  = df['Alpha3'].str.strip().str.upper()\n",
        "    # convert Numeric: remove leading zeros, convert to int if possible\n",
        "    df['Numeric'] = pd.to_numeric(df['Numeric'], errors='coerce').astype('Int64')\n",
        "    # drop rows with missing Country or Alpha2/Alpha3 or Numeric\n",
        "    df = df.dropna(subset=['Country','Alpha2','Alpha3','Numeric'])\n",
        "    return df\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top‑N.\"\"\"\n",
        "    return df.sort_values(by='Numeric', ascending=False).head(top)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    html = pd.read_html(URL)  # or use requests + html content\n",
        "    df = q1_read_table(html=URL)  # adjust if passing html text\n",
        "    df_clean = q1_clean(df)\n",
        "    top15 = q1_sort_top(df_clean, top=15)\n",
        "    print(top15)\n",
        "    df_clean.to_csv(\"data_q1.csv\", index=False)\n",
        "\n",
        "\n"
      ],
      "id": "q1_skeleton_answer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmefu--_u-tg"
      },
      "source": [
        "## Question 2 — Hacker News (front page)\n",
        "**URL:** https://news.ycombinator.com/  \n",
        "**Extract at least:** `rank`, `title`, `link`, `points`, `comments` (user optional)  \n",
        "**Clean:** cast `points`/`comments`/`rank` → **int** (non-digits → 0), fill missing text fields  \n",
        "**Output:** write **`data_q2.csv`** and **print a Top-15** sorted by `points` (desc, no charts)  \n",
        "**Tip:** Each story is a `.athing` row; details (points/comments/user) are in the next `<tr>` with `.subtext`.\n"
      ],
      "id": "rmefu--_u-tg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q2 Skeleton (fill the TODOs) ---\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    TODO: implement with BeautifulSoup on '.athing' and its sibling '.subtext'.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_parse_items\")\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\n",
        "    TODO: cast points/comments/rank to int (non-digits -> 0). Fill text fields.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_clean\")\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N. TODO: implement.\"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_sort_top\")\n"
      ],
      "id": "q2_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2_skeleton_answer"
      },
      "outputs": [],
      "source": [
        "# Q2 — Write your answer hereimport requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    rows = soup.select('tr.athing')\n",
        "\n",
        "    data = []\n",
        "    for row in rows:\n",
        "        rank_tag = row.select_one('.rank')\n",
        "        title_tag = row.select_one('.titleline a')\n",
        "        subtext_row = row.find_next_sibling('tr')\n",
        "        subtext = subtext_row.select_one('.subtext')\n",
        "\n",
        "        # Extract fields\n",
        "        rank = rank_tag.text.strip().strip('.') if rank_tag else '0'\n",
        "        title = title_tag.text.strip() if title_tag else ''\n",
        "        link = title_tag['href'] if title_tag and title_tag.has_attr('href') else ''\n",
        "\n",
        "        points = 0\n",
        "        comments = 0\n",
        "        user = ''\n",
        "\n",
        "        if subtext:\n",
        "            points_tag = subtext.select_one('.score')\n",
        "            user_tag = subtext.select_one('.hnuser')\n",
        "            comments_tag = subtext.find_all('a')[-1] if subtext.find_all('a') else None\n",
        "\n",
        "            points = points_tag.text.replace(' points', '') if points_tag else '0'\n",
        "            user = user_tag.text if user_tag else ''\n",
        "            if comments_tag and 'comment' in comments_tag.text:\n",
        "                comments = comments_tag.text.replace('\\xa0comments', '').replace(' comments', '').replace(' comment', '')\n",
        "\n",
        "        data.append({\n",
        "            'rank': rank,\n",
        "            'title': title,\n",
        "            'link': link,\n",
        "            'points': points,\n",
        "            'comments': comments,\n",
        "            'user': user\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\"\"\"\n",
        "    for col in ['rank', 'points', 'comments']:\n",
        "        df[col] = pd.to_numeric(df[col].apply(lambda x: re.sub(r'\\D', '', str(x))), errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    text_fields = ['title', 'link', 'user']\n",
        "    for col in text_fields:\n",
        "        df[col] = df[col].fillna('').astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N.\"\"\"\n",
        "    return df.sort_values(by='points', ascending=False).head(top)\n",
        "\n",
        "# --- Run everything together ---\n",
        "if __name__ == '__main__':\n",
        "    url = \"https://news.ycombinator.com/\"\n",
        "    response = requests.get(url)\n",
        "    html = response.text\n",
        "\n",
        "    df_raw = q2_parse_items(html)\n",
        "    df_clean = q2_clean(df_raw)\n",
        "    df_top15 = q2_sort_top(df_clean, top=15)\n",
        "\n",
        "    df_clean.to_csv('data_q2.csv', index=False)\n",
        "    print(df_top15[['rank', 'title', 'link', 'points', 'comments']])\n",
        "\n",
        "\n"
      ],
      "id": "q2_skeleton_answer"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}